{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine (SVM) Modeling\n",
    "\n",
    "In this notebook, we iterate through an SVM baseline, trying different class imbalance remedy methods. We also grid search to try and optomize the baseline's hyperparameters.\n",
    "\n",
    "The idea behind SVMs is that you perform classification by finding the seperation line or (in higher dimensions) 'hyperplane' that maximizes the distance between two classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import seaborn as sns; sns.set()\n",
    "%matplotlib inline\n",
    "import nltk\n",
    "from sklearn.feature_extraction import text \n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn import metrics, model_selection, svm\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, plot_confusion_matrix, roc_curve, auc, classification_report\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing X and y from `nlp_preprocessing.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_lem = pickle.load(open('../pickle/X_lem.pkl', 'rb'))\n",
    "y_lem = pd.read_pickle('../pickle/y_lem.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up stop words\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Test Split & Vectorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_lem, y_lem, test_size=0.20, random_state=15)\n",
    "\n",
    "# using tf_idf vectorizor with bigrams\n",
    "tfidf = TfidfVectorizer(stop_words= stop_words, ngram_range=(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sparse matrix format with 265K stored elements\n",
    "tfidf_data_train = tfidf.fit_transform(X_train)\n",
    "tfidf_data_test = tfidf.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM Baseline\n",
    "\n",
    "SVM Hyperparameters:\n",
    "- `C` is the regularization parameter, `1.0` is the default.\n",
    "- `kernel` specifies the kernal type to be used in the algorithm, default is `rbf`. These are different ways of drawing non-linear boundaries around classes.\n",
    "- `degree` is the degree of the polynomial kernal functions (`poly`), ignored by all other kernals.\n",
    "- `gamma` is the kernal coefficient for `rbf`, `poly` and `sigmoid`, default is `scale`.\n",
    "- 'class_weight' default 1. If balanced, it uses the values of y to automatically adjust weights inversely proportional to class frequencies in the output data as `n_samples / (n_classes * np.bincount(y))`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM_baseline = svm.SVC(C=1.0, kernel='linear', degree=3, gamma='auto', class_weight='balanced', random_state=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 36.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "# this cell takes about 53 seconds to run\n",
    "# fit the training dataset on the classifier\n",
    "SVM_baseline.fit(tfidf_data_train, y_train)\n",
    "# predict the labels on validation dataset\n",
    "SVM_test_preds = SVM_baseline.predict(tfidf_data_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_precision = precision_score(y_test, SVM_test_preds)\n",
    "baseline_recall = recall_score(y_test, SVM_test_preds)\n",
    "baseline_f1_score = f1_score(y_test, SVM_test_preds)\n",
    "baseline_weighted_f1_score = f1_score(y_test, SVM_test_preds, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Metrics for SVM Baseline with Lemmatization & TF-IDF Vectorization\n",
      "Accuracy: 0.3609\n",
      "Precision: 0.3609\n",
      "Recall: 0.4373\n",
      "F1 Score: 0.3955\n",
      "Weighted F1 Score: 0.9281\n"
     ]
    }
   ],
   "source": [
    "# printing evaluation metrics up to 4th decimal place\n",
    "print('Testing Metrics for SVM Baseline with Lemmatization & TF-IDF Vectorization')\n",
    "print('Accuracy: {:.4}'.format(baseline_precision))\n",
    "print('Precision: {:.4}'.format(baseline_precision))\n",
    "print('Recall: {:.4}'.format(baseline_recall))\n",
    "print('F1 Score: {:.4}'.format(baseline_f1_score))\n",
    "print('Weighted F1 Score: {:.4}'.format(baseline_weighted_f1_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating dictionary with all metrics\n",
    "metric_dict = {}\n",
    "metric_dict['Baseline SVM'] = {'precision': baseline_precision, 'recall': baseline_recall, 'f1_score': baseline_f1_score, 'weighted_f1': baseline_weighted_f1_score}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x2693e17caf0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUMAAAEJCAYAAAAO8EUNAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAAhgUlEQVR4nO3de7wVVf3/8dc+h4snEBC5iCCKCh/MNLxgWXkvy/yaqaAIapR6NC/p18xS8QJF9rVQzCSDb6g/SbG89CvR0sISNStLMsQ+eQEEREUuIiB4zt7z/WPmwOF0zp7ZA5t99t7v5+Mxj/ZeM3tmTUc+j7VmzVqfTBAEiIhUu5pSV0BEpD1QMBQRQcFQRARQMBQRARQMRUQA6FDqCrSiMzAcWAZkS1wXkUpUC/QD/gps3Irz9AS6JTx2DbByK65VdO0xGA4H5pS6EiJV4DDgqZS/7RnkVq/I1PRIevwqYG/acUBsj8FwGUBuxSjIvVnqumxTNb3/QG75kaWuRlF86VPDSl2ForjbJ3OmXVrqamxTvfr35ObZ10L0by2lbpmaHjSuOC3+32nNLnTY+b6dCFuRCoYFCLvGuTchu7TEVSmCSrwn4K3XB5S6CkXz1uvvlLoKxbLVj6Eas0sJYv6bztRm22Wgaakc6igi7VSOgIBc3mMylMcsNwVDEUktGwTETenNlMmUXwVDEUktbBfmD3Y1ahmKSKXLJgiGgYKhiFS6XIJgiIKhiFS6xiAgG/NMsFbPDEWk0mUJyKplKCLVLhdANibWZcojFioYikh6uWiLO6YcKBiKSGpZMmTJ5D0mE7O/vVAwFJHUGoMMDUFMsIvb304oGIpIaklahjVqGYpIpcsFGXIxLb+4/e2FgqGIpJZL0DKsVctQRCpdlhqyMdlD4va3FwqGIpJaLojvBuf0nqGIVLoGavkgqM17TIb8+9tiZt8Herv7WDMbBkwDugNPAue7e6OZDQRmAH0AB8a4+1oz6wH8DNgTWA6c6u55l+Quj/ariLRLOWoSbYUys2OAsc2KZgAXu/sQIAOcG5VPAaa4+1DgOeCaqPw7wBx334cwiN4Sd00FQxFJrWkAJd+WK3AAxcx6AhOB70bfdwfq3P3Z6JA7gZFm1hE4HLi/eXn0+XjCliHAvcBx0fFtUjdZRFLLBhmyQcwASvRMcerUqQMmTZrUcvdqd1/douwnwNXAbtH3XdkyedUyYADQC1jj7o0tyrf4TdSdXgP0Bt5oq55qGYpIarmo5Re3AcycOXMOsKDFdmnz85nZOcBid/99s+LWmpa5POX5ftMmtQxFJLWGoAMfBPnDSG20f9SoUYdNmjRpSYvdq1t8Pw3oZ2ZzCZPUdyVcA2yXZsf0I2zhLQe6mVmtu2eblQMsjX6zxMw6EKYpXZGvngqGIpJakgGSpv319fVL6uvrF+Y71t0/0/TZzMYCR7r7l81snpl90t2fBs4CHnX3BjObQxhA72kqj37+SPT9u9H+Oe7ekO/aCoYiklq4nuF2ec9wDDDNzHYEngd+GJVfANxlZuOA14HTo/JrgDvN7EXC1ueYuAsoGIpIasWcgeLudxKOEOPu/wAOaeWYRcCRrZSvBL5QyPUUDEUktVxQQy5mNDluf3uhYCgiqeUStAzTvHRdCgqGIpJaQ1BDQ8x0vAa1DEWk0uWCmtiXrtVNFpGKl0sw3a7Q6XilomAoIqllE7QM4/a3FwqGIpJauFBD3ACKWoYiUuFyJMiBomAoIpWuMehAQ8zc5MaY/e1FedRSRNqlJKlC4/a3FwqGIpJamCo07tUaBUMRqXBJUoXqmaGIVDzNTRYRARqD2tjpeI0x+9sLBUMRSa2QHCjtnYKhiKQWDqDELe6qYCgiFa4YS3iZ2QRgBGHuk5+6+01mNh04DFgXHTbe3R8ys08DNwF1wH3uPi46xzBaSTqf77rl8WRTRNqlppZh3JaUmR0BHA3sDxwMXGxmBgwHDnf3YdH2kJnVAdOBE4F9gOFmdlx0qraSzrdJwVBEUmtKCBW3JeXufwSOilpxfQh7rxuAgYQ5UF4ws/FmVkOYBuBld18QHT+DMLl8q0nn466tbrKIpNYYZGjI5Q92jQUmkY+y3o0HLgd+QRinZgPnAWuBh4Gzo8+tJZdvK+l8XmoZikhqTe8Zxm2QLIl8E3e/DugN7AYc4+4nufvb7r4euBX4POmSy7dJwVBEUmuamxy3QZhEHhjUYpvc/HxmNjQa/CAKfA8Cp5nZKc0OywANbE4U36QpiXxb5Xmpm7yNrH6nAxd+dgg3zHyVgYM3AjD7wR786o7eTP71ywD85dHnufuawQQBDN7/fS767hLWv1fD/1y0O+vX1tLYkKH+uqV8+OD1pbyVqlLbIcdlNy6g74CNdOwUcO+PduXZ3+0EQP24RQTr79107MFHrGbMJUvJZODlf3bhtmt3p/VGSPUIEgyQBNH+JEnkgT2B8Wb2KcLR5BOBPwKTzWw2Yde4HrgL+DNgZrY3YStzNDDd3ReZ2YaWSefj7qWowdDMRgPjgE7Aze5+WzGvVyqNDXDLFQPoXLe5Jf7KP+v47cydCaIE2uvX1jDtiru5ceZrdN85y89v68O7K2v51fTeDDtsLSefu5zFr3Tmexfszm2P/btEd1J9jv7iCtas6sD3L9uLrt0bmTJrHi/9vSuXT3qN/oM2bDqurkuWc65czBWnD2XNqo6MOG8Z3Xs28u7KjiWsfelt6+l47v6ImX2MMFF8FnjA3SeY2TvA00DHqOxeADMbCzwA7AA8AtwfnaqtpPNtKlowNLP+wETgIGAj8IyZPeHu84t1zVKZNqE/x5+1gvtu7QvAmpW13PG9fpw/fimTv7EbAPOf68Ie+w1k6oT+LFvUieNGr6DHzllOrl9Ox05hEM1mM3TsHJTsPqrRnEd68tSjPQHIZAKy2Qw7fCjHjFv6M/yI1Zy5X3jchw96j4Vex7lXv06/gRv5zczeVR8IoTg5UKLnhde1KJsCTGnl2N8DH22lvNWk8/kU85nhp4HZ7r7S3dcRRuwRRbxeSTx2X0+679zIwUe+B0Aul+Gmrw/kvOuXUtd1c0txzcoO/OOJeZx99RtM/NlrPDStN0te7UzX7lk61wWsfLsDN140kK9cFftoQ7ahDetreX9dLXVdsoyb8gp3TerPW0s643O7bnFct50a2f/Q95j+vd0YN9b44lfeov+g90tU6/ajMVdDQ64279YYM9rcXhSzm9za8HbiSF3T+w/buj5F8diD10IGnj89w6vzF3L+0Tuyy6A+3HrtoXywoYHXX17C7d8byfDPDcOG/5Ze+/8vAPsdPZ0FS4cy8JOfYME/FzFx9GTqv38Ww447oMR3lM5jZRwXguwyglUXkvnQlRxw0giuispz74U9q8fen0Gw8UmC9T/jvsU/Cfet+Q7T/3YgmbrPl6jW7YOm4yWTanh704HLj4Ts0m1XmyL5wX2bP3/jlL25+HuLGTj4eQDeXNyJG766O+d/67usfqcDC+cdxaoXh9K1e5aXnhrMcSctZsGTARPOHsRVty9kr30fJvdmiW5kK31u0MdKXYVUevRq4MZ7X2LKdbsz95lfAr/ctO+MS5Zw5rXncWzdGXTfuYFbHnqRr514GmvXdOCm++dz8zf/zqJ/31OqqqfWd2Av7vbJ2+RcShWazFLCuYRNEg1vV6oevRr5ynfHcNXoRQAcfsJq9hi6gevGDqJhYw23Xxu+E/qhHbOMv3NBKataVUZd8AZdu2cZffEbjL44/M9z3Fjjg41bdu3eXdGRO27cjYl3OQBPzurJon9/aLvXt72ppIRQmSAozgP7aADlKcKu8TrgGaDe3f8S89M9gAXl0jIsRM0uL5N7c3Cpq1EU5doyjPPY+zM4tu6MUldjm2rWMhwELEx5mj2ABRf9/WqWb1yR98DenXfmRwdO3NrrFV3Rnmy6+1LgauAJYC5wT4JAKCJlpDHI0BjUxGzl0TIs6nuG7n4PUH4PVUQkEQ2giIhQ2AyU9k7BUERSU8tQRAQFQxERQO8ZiogAYea7uOl2yo4nIhVP3WQRERQMRURCQSb+1RkFQxGpdBpAERGhON3kNpLIF5Qs3swGEqYO7QM4MMbd1+a7bnmsuigi7VI2V5NoS6qNJPIfpfBk8VOAKe4+FHgOuCbu2gqGIpJeEE63y7dRwMJYbSSR70EByeLNrCNwOJvzodyJksiLSDEVsp7hViSRbyspfFvlvYA1UeBsXp6XWoYikloQJNtgq5LIt7YIaL5k8UoiLyLbV9NoctwGW5VE/igKSxa/HOhmZrUtyvNSMBSR1HIJBk9y0QBKfX39Endf2GJb3eKUexLmO+5sZp0IB01+QpQsPgpwo4FH3X0RsMHMPhn99qyovAGYA5zWvDzuXhQMRSS1QrrJSbj7I4TJ4J8H/gY84+4zgbGEyeLnA/9iy2TxN5vZS0AXNieLvwCoN7P5hLmYxsVdWwMoIpJakGAGSqGLu7aRRL6gZPFRq/HIQq6rYCgiqRUjGJaKgqGIpKaFGkRECN+njnsmWJxkxNuegqGIpBbkMptGi/MdUw4UDEUktYD4ll/ZtwzNrGe+H7r7ym1fHREpJ9UygPIOYVBv7U4CoLaVchGpJhXUNGwzGLq7XsgWkbyqpWUIgJnVAJcBHwEuBi4CbnT3bJHrJiLtXC6XIRczQBK3v71IMoDyfcLVI4YTTt/7HOHE568VsV4iUhYyCXKclEcwTNIVPoZwXuAGd38XOBb4TDErJSLlYVvPTS6lJMGwwd03rQXm7huBxjzHi0i1CBJuZSBJN3memV0I1JqZET4/nFvUWolIWaikAZQkLcNLgAOBvsDTQFfaWJ1WRKpMNbUM3X0NcPZ2qIuIlJtcJn66XaWMJptZH+AWwkGTBsKFF7/eygq1IlKVyiPYxUnyzHAaMI9wAcUa4HzCZbhPy/cjEakCRZiBYmbXAadGX2e5+xVmNp1wxep1Ufl4d3+o0OTy+a6bJBju4e4nNvt+uZn9M+F9iUil24bPBKPgdixwQHTm35jZSYTvOR/u7suaHVtHmFz+CGAxMMvMjnP3RwlzK5/j7s+a2U8Jk8v/ON+1kwygvGFmg5pVYABb5ioVkWoVZJJtyS0jfAz3QZTY6SVgYLRNM7MXzGx8NDPuEApILh934Xyr1vyaMDL3Buaa2e+ALGHavhcKuTsRqUxJXqpu2p8kiby7v9j02cwGEz6O+xRhPpPzgLXAw4SDumspLLl8Xvm6yfe3UT4r7qQiUiVymfjR4mh/lES+pfHA9S0LzWxfwlhzubs7cFKzfbcSpv/8RWtXI2US+Xyr1tzVWrmZZYC9404sIpUvE4Rb3DEQJpGfNGnSkha7V7c8PsqD/ABwqbvPNLP9gCHu/kDTKQnfbGkriXxb5XklebXmPMLFGro0K17e4mIiUo0KGE2ur69fUl9fvzDfoWa2G/BL4DR3nx0VZ4DJZjabsGtcD9wF/JkouTywgDC5/HR3X2RmG8zsk+7+NAmTyCcZTf4W4TuGVxMmYj6BBP1vEakCSQZIChtAuRzYAbgpnP0LwO3ADYQz4DoCD7j7vQBmNpawFbkD4TvQzZPLTzOzHQkT0jcll29TkmC40t3/bGZzgb7uPtHM/pbsvkSk4m3DV2vc/RLCKcCtmdLK8QUll88n0ao1ZrYT8HKzk3ct5CIiUqFyCbcykKRlOJVwKPsEwldsTgL+VdRaiUh52Pbd5JKJbRm6+3Tg2Cgb3qHAt9FUPBEBCDaPKLe1lf2qNWZ2WYvvzb9eQDgfUESqWTVkxwP2y7OvTG5PRCSZfC9df3l7VqSlsz6+H28tqqxXGR9vhM8OOKjU1SiO3MZS16Bogo2VdW/BBx9ss3MV8tJ1e5dkAEVEpHVBgul4ZTKAomAoIulVyTNDEZG8qqqbHK0b9nXgI8BF0Xaju2eLXDcRae+qrGX4fcI1DYcTTpj+HOEqEF8rYr1EpBxUUDBMMh3vGGAssCHKlHcs4cINIlLl4l64TtKNbi8SzU12902zC919I5A3sYqIVImmxV3jtjKQpJs8z8wuBGotnIZyGTC3qLUSkbKQIcEAynapydZL0jK8BDgQ6Eu4nlhX4NIi1klEykWQcCsDsS3D6Dnh2duhLiJSZqrt1ZpWV4h1d40mi1S7ChpNTvLMcEWzz50IR5OfKU51RKScZHLhFndMIczsOuDU6Ossd78iSi5/E1AH3Ofu46JjhwHTgO7Ak8D57t5oZgMJ8yj3ARwY4+5r8103yXqG45ttVxPmL92/sNsTEYkXBb1jgQOAYcBBZnY6MB04EdgHGG5mx0U/mQFc7O5DCMdqzo3KpwBT3H0o8BxwTdy1kwygbMHd1wH9C/2diFSgAgZQpk6dOsDM9mix9WhxxmXA1939A3dvAF4ChgAvu/sCd28kDIAjzWx3oM7dn41+e2dU3hE4nM3Joe4ERsbdSpJnhrduvh0ywEFRBUWkyhUygJIkiby7v9j02cwGE66q/0PCINlkGWGGzl3bKO8FrIkCZ/PyvJK0DN8hfG64gjBf8t3AmQl+JyLVIOFrNaNGjToMGNRim9zaKc1sX+BxwtShr7ZySI7WX2HMV55XkgGUvdz9rATHiUi12cZJ5AHM7JOEuZAvdfeZZnYE0Hyl537AG8DSNsqXA93MrDZaUKapPK8kLcP9zaxcXiIXke0pt3lEua2tkFShZrYb8EtgtLvPjIr/HO6yvc2sFhgNPOrui4ANUfAEOCsqbwDmsDlx3VnAo3HXTtIyfBN40cyeBTYNTes9QxEpwkvXlwM7ADc1S0J3O+FiMQ9E+x5h8+DIGGCame0IPE/4fBHCpHV3mdk44HXg9LgL58uO1zlalOFP0SYisqVt/NK1u19COAW4NR9t5fh/AIe0Ur6I8DXAxPK1DP8EHOju4ws5oYhUkSqZgaLnhCKSV7XMTd7BzA6gjaDo7n8vTpVEpKyUSbCLky8Y7kn4wLK1YBhE+0WkihVjbnKp5AuG8939gO1WExEpP1XyzFBEJK9qeWb45HarhYiUp2poGUbv+4iItK0agqGISJxq6SaLiORVSdnxFAxFJD11k0VEUDAUEQE9MxQRCallKCLCpsVd444pBwqGIpKauskiIk2KEOzMrBvwDPBf7r7QzKYDhwHrokPGu/tDhSaXz3fNgvMmi4hsUkDe5KTM7GPAU4T5kpsMBw5392HR9pCZ1VF4cvk2qWUoIqkV0k2eOnXqgEmTJrXcvdrdV7coOxe4kDAtMWbWBRhImOtkIPAQYb7lQ4iSy0fHNSWXn89/JpcfD/w4Xz0VDEUkvQJGk5MkkQdw93MAmiWE6gvMBs4jTEr3MHB29LmQ5PJ5KRiKSGqZXEAmlz8aNu0fNWrUYZMmTVrSYvfquGu4+2vASU3fzexWwvSfv2jl8KImkRcRaVUh3eSkSeRbMrP9gCHu/kDTKYEG2k4i31Z5XhpAEZH0ijCA0ooMMNnMdjKzjkA94XPDgpLLx11EwVBEUmtatSbvtpXXcPcXgBuAp4H5wFx3v9fdN7A5ufx84F9smVz+ZjN7CejC5uTybVI3WUTSK+J0PHffo9nnKcCUVo75PQUkl89HwVBEUquW7HgiInlpOp6ICEAQhFvcMWVAwVBE0kvQMtQSXiJS+bSeYTItV54o5rXaEztgHWdftZQrRg5hr33XM+GuV1m6oDO5FWdwxAkrWfdeLade+BYAmQzsO3wt5x2zD4tfqStxzauXHbCOs69exhUj9mbPfd/nwu8sJZuF3Mqv0KNXA6vf6chJ5y7nyBNXA/CX2Tvys5t2yX/SKpAJEgygVHswjFaemMaWK09UvJFffZNjTlnJhvXhK5yD91/Pg1P78MDUvjzeOIM//noUAM/9oTsAI85/i/l/7aJAWEIjL3ibY05Ztelv9tUJS7ltXH9ee7GOx9Yey6kX/pBf3dGLo09exSXHDyaXg5v+/ys882h3FrxU3X+3ShpNLuZL100rT8ROg6kkyxZ1ZsK5e276Pni/9RxyzLv84P5/k3v3Kuq6ZDft69XvA445ZQUzbu5XiqpKZNnCTkw4Z49N32/46u689mIU5IJGGjbWsPyNTlw9Zk9yuQyQoUOHgA82as7CpgGUuK0MFO2v6e7nuHtrq1RUtKce2Ylsw+Z37n1uF6Z9ZwCXjxhCpnY3zvjvzYtpnHzu2zw0rS8NH+gfVSk99UiPLf5mK9/uCMCHD15HsH4GD07tTbYxw5qVHYCAc699g1fm1bH0tc4lqnH7ETv7JMkASzvRbgdQZrx6a6mrkFrQuITg3f/m8caZBLk1ZGq6ReWvMOJrf+LU6/8fQZAjeOdzZHr9im/cs0OJayyb/ma5cCGU4P1ZBOtuJ9Pjdu5/Z2BYFmwkePdKyOxDptv1nPCN2lJWuX3QAErxnbHXxby1aHmpq5FK3wEbuXLKAi79wihu+fW/mHLNbvjcLjz27uf5+S2v8dOJoxi0z3q+9I1VXP+VsaWu7raRy8Yf0471HfABV/54EZeeMJKjT17F8Weu4Pov78GDKwfymZqRQMDEe17jH0/vyM9v6wOMKnWVU+u7e29mLPiPmW2p6KVrSezWKwdywbcX09iYIWjYhXtvCZ8PDthzI2++3qnEtZOWamoCLvj2Ut5+oyPX/O9CcivO4MzL3+TVeXXs//F1dOwUcPBRawC444Z+vPS3LiWucWllggTrGZbJM0MFwyJ4a0lnLv3CUABemfchLjspXLH38cbJrF8btijmzNqJObN2KlkdZUtvLenEpScMBmDEvh/ZVP54bgZ3/2AkACfsuX9J6tauqZucXPOVJ0SksqibLCICkAvCLe6YMqBgKCLpqZssIlK8bnIrSeQLShYfpRSdAfQBHBjj7mvzXVNv+4pIetFocr6t0BkoLZPIp0wWPwWY4u5DgeeAa+Kuq2AoIukVkBBq6tSpA8xsjxZbj1bO2nIq76Zk8e7eSBgAR5rZ7vxnsviRUdKow9mcD+VOYGTcraibLCKphd3kuPcMw//diiTybSWFb6u8F7AmCpzNy/NSy1BE0ssl3AiTyAODWmyTE1ylraTwhZbnpZahiKSWCYIELcNwf9ok8hSeLH450M3Mat09i5LIi0jRbZ8k8gUli3f3BmAOcFrz8riLKBiKSGqZBKPJWzs3OWWy+AuAejObDxwGjIu7jrrJIpJeEbPjtUgiX1Cy+KjVeGQh11MwFJHUKmnZfwVDEUlPeZNFRNDcZBERgEyQI5PL3w/OBOXRT1YwFJH0mr1UnfeYMqBgKCKpFfLSdXunYCgi6QUkGEDZLjXZagqGIpKeRpNFRNAzQxER0GiyiEhI3WQRERQMRUQAPTMUEQHChFBqGYpI1VM3WUQEyAWQjekH5xQMRaTSFaFlaGazgb5AQ1R0HrAX4WrVnYCb3f226NhWk8unoWAoIult42BoZhlgKDCwKdWnmfUHZgIHARuBZ8zsCWABYXL5I4DFwCwzO87dY/OdtEbBUETSywXx3eBo/9SpUwdMmjSp5d7V7r662XcjnM38qJn1AaYB7wGz3X0lgJndD4wA/kiUXD4qn0GYLD5VMFRCKBFJL8gl29iURH5Bi+3SFmfcCfg98EXgGOB8YCCFJZFPRS1DEUmvgAGUUaNGHTZp0qQlLfaubv7F3f8E/Cn6us7Mfkr4THBiy7OSMll8WxQMRSS9Ap4ZJkkib2afAjpH2fAgDHgLKSyJfCoKhiKS3rYfTe4BTDCzTwAdgS8BZwAzzKw3sA44BagHXiBKLk/Y5R5NOKCSip4Zikh6TcEwbkvI3R8GZgHPA38Dprv708DVwBPAXOAed/9LTHL5gqllKCLp5XLhFndMAdz9GuCaFmX3APe0cmyryeXTUDAUka2QpOWnGSgiUumyCUaTswqGIlLpghxB3ErWWulaRCpeATNQ2jsFQxFJT0t4iYgQdoHjRovVTRaRiqeWoYgIBNkcQTYbe0w5UDAUkfQ0gCIiApBL8ExQLUMRqXBBLiCIafnF7W8vFAxFJL0giG8ZagAltVqAXv17lroeRdF3996lrkJx5PI/RC9nlfY3a/Zvq3Zrz7Vzvx6xAyg79+uxtZfZLjJB+4vanwLmlLoSIlXgMOCplL/tCbxCuEx/EquAvYGVKa9XdO0xGHYGhhPmM6jc5oZI6dQSrgr9V8Jsc2n1BLolPHYN7TgQQvsMhiIi251WuhYRQcFQRARQMBQRARQMRUQABUMREUDBUEQEUDAUEQHa53S8imRmo4FxQCfgZne/rcRVkhhm1g14Bvgvd19Y4upIkalluB2YWX9gIuFUw48C9Wb24dLWSvIxs48RTlUbUuq6yPahYLh9fBqY7e4r3X0dcD8wosR1kvzOBS4E3ih1RWT7UDd5+9iVcK51k2XAISWqiyTg7ucAmFmpqyLbiVqG20emlbLyWP5XpEooGG4fS4Fdmn3vh7pfIu2Kusnbx++A682sN7AOOAWoL22VRKQ5tQy3A3dfClwNPAHMBe5x97+UtFIisgWtZygiglqGIiKAgqGICKBgKCICKBiKiAAKhiIigN4zLBtmtgfwKvDPZsUZ4BZ3n76V534YuN/d7zSzucCR7r66jWO7Aw+5+9EFXmMEcJG7H9mi/EjgR+7+kZjfB0Bvd3+ngGveCcxz9x8UUlepTgqG5eV9dx/W9CVaDWeemT3n7i9siws0P38bdkLzqqUCKRiWMXdfamYvA0PM7EDgbKAL8K67H2VmZwMXED4OWUHYMvuXme0K3EW4gMQioE/TOZu3wMzsSuBLQCPwMjAWuAOoi1qQBxEucXULsDNhcvIfNrVUzWwCMCa69stx92NmQ4DbgK5R3eYCp7n7huiQiWY2PLqfce7+cPS7Vu+zgP8rRfTMsJyZ2aHA3sCfo6J9Cbu4R5nZEYSB7DB3PwC4EXgwOu424Fl33xf4GjC0lXN/gTD4HRp1YRcAFwFfZnMLNUO4HNm33P0g4AjgcjP7uJmdSDjtcBjwCaB7gls6F7jL3ZvuaxBwfLP9r7n7gcAZwF1m1jvmPkUSU8uwvDS1yCD8270DjHH3xdFSUy+4+5po//GEAeWZZstQ9TSznoTrK14O4O6vmNnsVq71aeAX7r4qOu4y2PTssskQYC9gerNr1AEHAB8GHnT396LfTScMvPl8E/iMmV0RnXtXwlZik9ujuswzs/nAoYQL5rZ1nyKJKRiWl/djnumtbfa5Frjb3b8JYGY1hMFlFRCw5bJija2cqzE6juj3PYAeLY6pBVa3eI7ZF3iXsIUWd42W7iX8b/LnwCxgYItzZJt9zgAN5L9PkcTUTa5cjwGnm1m/6Pv5wO+jz78hWjXHzAYCR7Xy+98BJ0d5QACuBy4jDGq1ZpYBHNhgZmdE59oNmEf4LPE3wEgz6xEFqDMT1PmzwAR3v48wEH+MMNg1GRtd50BgMOHjgXz3KZKYWoYVyt1/a2b/AzxuZjlgDXCyuwdmdiFwh5m9BCwhHKho+ftHojwtT0fdzxcJn+mtB/4OvAR8EjgRuCXq2nYErnH3pwHMbD/gOcJW2j+A3jHVvgp4yMxWRtf5I2EXuMmeZvY8YaAc5e4rgXz3WcD/Y1LttGqNiAjqJouIAAqGIiKAgqGICKBgKCICKBiKiAAKhiIigIKhiAigYCgiAsD/AdNqRlwecCtEAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(SVM_baseline, tfidf_data_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline with SMOTE\n",
    "Used to over-sample the minority class (hate speech)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "sm= SMOTE()\n",
    "smote_X_train, smote_y_train = sm.fit_resample(tfidf_data_train, y_train)\n",
    "# sm = SMOTE(random_state=35)\n",
    "# smote_X_train, smote_y_train = sm.fit_sample(tfidf_data_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote_SVM = svm.SVC(C=1.0, kernel='linear', degree=3, gamma='auto', random_state=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# this cell takes about 4 minutes to run\n",
    "smote_SVM.fit(smote_X_train, smote_y_train)\n",
    "smote_SVM_test_preds = smote_SVM.predict(tfidf_data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote_accuracy = accuracy_score(y_test, smote_SVM_test_preds)\n",
    "smote_precision = precision_score(y_test, smote_SVM_test_preds)\n",
    "smote_recall = recall_score(y_test, smote_SVM_test_preds)\n",
    "smote_f1_score = f1_score(y_test, smote_SVM_test_preds)\n",
    "smote_weighted_f1_score = f1_score(y_test, smote_SVM_test_preds, average='weighted')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Metrics for Oversampled SVM Baseline with Lemmatization\n",
      "Accuracy: 0.9296\n",
      "Precision: 0.3438\n",
      "Recall: 0.276\n",
      "F1 Score: 0.3062\n",
      "Weighted F1 Score: 0.926\n"
     ]
    }
   ],
   "source": [
    "# printing evaluation metrics up to 4th decimal place\n",
    "print('Testing Metrics for Oversampled SVM Baseline with Lemmatization')\n",
    "print('Accuracy: {:.4}'.format(smote_accuracy))\n",
    "print('Precision: {:.4}'.format(smote_precision))\n",
    "print('Recall: {:.4}'.format(smote_recall))\n",
    "print('F1 Score: {:.4}'.format(smote_f1_score))\n",
    "print('Weighted F1 Score: {:.4}'.format(smote_weighted_f1_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like SMOTE actually decreased the F1, which also happened with Logistic Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding these metrics to evaluation metric dict\n",
    "metric_dict['Baseline SVM Oversampled with SMOTE'] = {'accuracy': smote_accuracy, 'precision': smote_precision, 'recall': smote_recall, 'f1_score': smote_f1_score, 'weighted_f1': smote_weighted_f1_score}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline with Tomek Links\n",
    "Used to under-sample the majority class (not hate speech)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled dataset shape Counter({0: 18627, 1: 1151})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from imblearn.under_sampling import TomekLinks # doctest: +NORMALIZE_WHITESPACE\n",
    "\n",
    "tl = TomekLinks()\n",
    "tomek_X_train, tomek_y_train = tl.fit_resample(tfidf_data_train, y_train)\n",
    "print('Resampled dataset shape %s' % Counter(tomek_y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only removed 48 values from the majority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tomek_SVM = svm.SVC(C=1.0, kernel='linear', degree=3, gamma='auto', random_state=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 31.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# this cell takes 42 seconds to run\n",
    "tomek_SVM.fit(tomek_X_train, tomek_y_train)\n",
    "tomek_logreg_test_preds = tomek_SVM.predict(tfidf_data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tomek_accuracy = accuracy_score(y_test, tomek_logreg_test_preds)\n",
    "tomek_precision = precision_score(y_test, tomek_logreg_test_preds)\n",
    "tomek_recall = recall_score(y_test, tomek_logreg_test_preds)\n",
    "tomek_f1_score = f1_score(y_test, tomek_logreg_test_preds)\n",
    "tomek_weighted_f1_score = f1_score(y_test, tomek_logreg_test_preds, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Metrics for Undersampled SVM Baseline with Lemmatization\n",
      "Accuracy: 0.9498\n",
      "Precision: 0.6562\n",
      "Recall: 0.2258\n",
      "F1 Score: 0.336\n",
      "F1 Score: 0.938\n"
     ]
    }
   ],
   "source": [
    "# printing evaluation metrics up to 4th decimal place\n",
    "print('Testing Metrics for Undersampled SVM Baseline with Lemmatization')\n",
    "print('Accuracy: {:.4}'.format(tomek_accuracy))\n",
    "print('Precision: {:.4}'.format(tomek_precision))\n",
    "print('Recall: {:.4}'.format(tomek_recall))\n",
    "print('F1 Score: {:.4}'.format(tomek_f1_score))\n",
    "print('F1 Score: {:.4}'.format(tomek_weighted_f1_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding these metrics to evaluation metric dict\n",
    "metric_dict['Baseline SVM Undersampled with Tomek Links'] = {'accuracy': tomek_accuracy,'precision': tomek_precision, 'recall': tomek_recall, 'f1_score': tomek_f1_score, 'weighted_f1': tomek_weighted_f1_score}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics for All Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>weighted_f1</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Baseline SVM</th>\n",
       "      <td>0.360947</td>\n",
       "      <td>0.437276</td>\n",
       "      <td>0.395462</td>\n",
       "      <td>0.928112</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline SVM Oversampled with SMOTE</th>\n",
       "      <td>0.343750</td>\n",
       "      <td>0.275986</td>\n",
       "      <td>0.306163</td>\n",
       "      <td>0.925951</td>\n",
       "      <td>0.929595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline SVM Undersampled with Tomek Links</th>\n",
       "      <td>0.656250</td>\n",
       "      <td>0.225806</td>\n",
       "      <td>0.336000</td>\n",
       "      <td>0.937993</td>\n",
       "      <td>0.949768</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            precision    recall  f1_score  \\\n",
       "Baseline SVM                                 0.360947  0.437276  0.395462   \n",
       "Baseline SVM Oversampled with SMOTE          0.343750  0.275986  0.306163   \n",
       "Baseline SVM Undersampled with Tomek Links   0.656250  0.225806  0.336000   \n",
       "\n",
       "                                            weighted_f1  accuracy  \n",
       "Baseline SVM                                   0.928112       NaN  \n",
       "Baseline SVM Oversampled with SMOTE            0.925951  0.929595  \n",
       "Baseline SVM Undersampled with Tomek Links     0.937993  0.949768  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(metric_dict, orient='index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The baseline SVM with `class_weight=balanced` has the highest unweighted F1\n",
    "- The undersampled baseline has a lower raw F1, but higher weighted F1.\n",
    "\n",
    "We can take a look at each model's classification report to get a better idea about what's happening."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       0.97      0.95      0.96      4678\n",
      "     class 1       0.36      0.44      0.40       279\n",
      "\n",
      "    accuracy                           0.92      4957\n",
      "   macro avg       0.66      0.70      0.68      4957\n",
      "weighted avg       0.93      0.92      0.93      4957\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       0.96      0.99      0.97      4678\n",
      "     class 1       0.66      0.23      0.34       279\n",
      "\n",
      "    accuracy                           0.95      4957\n",
      "   macro avg       0.81      0.61      0.65      4957\n",
      "weighted avg       0.94      0.95      0.94      4957\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "target_names = ['class 0', 'class 1']\n",
    "# class_weight='balanced' Baseline report\n",
    "print(classification_report(y_test, SVM_test_preds, target_names=target_names))\n",
    "# Undersampled Baseline report\n",
    "print(classification_report(y_test, tomek_logreg_test_preds, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some differances. But most noteably, the baseline with `class_weight=balanced` predicts the hate speech (1) class much better than the other model. \n",
    "\n",
    "Therefore, let's stick with that one and grid search to tune its hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search\n",
    "\n",
    "The `sklearn` library provides an easy way to tune model parameters through an exhuastive search using `GridSearchCV`. It combines K-Fold Cross Validation with a grid search of hyperparameters.\n",
    "\n",
    "A full list of an SVC model's hyperparameters can be found in the documentation [here](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html).\n",
    "\n",
    "With this grid search, I aimed to improve the C and Gamma, and seeing if any other kernels outperform the Linear kernel.\n",
    "\n",
    "- More information about selecting the right C and gamma can be found in [this](https://www.quora.com/What-are-C-and-gamma-with-regards-to-a-support-vector-machine) Quora post.\n",
    "- More information about selecting the right SVM Kernel can be found in [this](https://towardsdatascience.com/svm-and-kernel-svm-fed02bef1200) TowardsDataScience article.\n",
    "\n",
    "The following hyperparamter dictionary was used and the grid search took about **48 minutes** to run. \n",
    "\n",
    "**Grid Searched Parameters:**\n",
    "- 'C': [1, 10, 100]\n",
    "- 'gamma': [0.1, 0.01, 0.001]\n",
    "- 'kernel': ['rbf', 'sigmoid']\n",
    "\n",
    "For the sake of reproducibility, the tuned model is below. The full code can be found in the `SVM.ipynb` notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the model\n",
    "baseline_model = svm.SVC(degree=3, class_weight='balanced', random_state=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating param_dict\n",
    "param_dict={'C': [1, 10, 100],  \n",
    "              'gamma': [0.1, 0.01, 0.001], \n",
    "              'kernel': ['rbf', 'sigmoid']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate Grid Search CV with F1 metric\n",
    "grid_baseline = GridSearchCV(baseline_model, param_dict, cv=5, scoring='f1', verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "[CV 1/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.433 total time=  18.7s\n",
      "[CV 2/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.465 total time=  19.4s\n",
      "[CV 3/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.446 total time=  18.7s\n",
      "[CV 4/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.456 total time=  18.7s\n",
      "[CV 5/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.405 total time=  18.1s\n",
      "[CV 1/5] END ....C=1, gamma=0.1, kernel=sigmoid;, score=0.439 total time=  19.7s\n",
      "[CV 2/5] END ....C=1, gamma=0.1, kernel=sigmoid;, score=0.451 total time=  20.0s\n",
      "[CV 3/5] END ....C=1, gamma=0.1, kernel=sigmoid;, score=0.441 total time=  19.8s\n",
      "[CV 4/5] END ....C=1, gamma=0.1, kernel=sigmoid;, score=0.450 total time=  21.9s\n",
      "[CV 5/5] END ....C=1, gamma=0.1, kernel=sigmoid;, score=0.400 total time=  28.7s\n",
      "[CV 1/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.360 total time=  25.1s\n",
      "[CV 2/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.416 total time=  24.8s\n",
      "[CV 3/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.390 total time=  25.2s\n",
      "[CV 4/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.376 total time=  24.5s\n",
      "[CV 5/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.367 total time=  24.6s\n",
      "[CV 1/5] END ...C=1, gamma=0.01, kernel=sigmoid;, score=0.165 total time=  24.0s\n",
      "[CV 2/5] END ...C=1, gamma=0.01, kernel=sigmoid;, score=0.164 total time=  24.3s\n",
      "[CV 3/5] END ...C=1, gamma=0.01, kernel=sigmoid;, score=0.157 total time=  24.2s\n",
      "[CV 4/5] END ...C=1, gamma=0.01, kernel=sigmoid;, score=0.109 total time=  24.0s\n",
      "[CV 5/5] END ...C=1, gamma=0.01, kernel=sigmoid;, score=0.185 total time=  23.6s\n",
      "[CV 1/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.034 total time=  24.9s\n",
      "[CV 2/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.110 total time=  25.7s\n",
      "[CV 3/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.110 total time=  25.8s\n",
      "[CV 4/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.110 total time=  27.8s\n",
      "[CV 5/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.110 total time=  25.0s\n",
      "[CV 1/5] END ..C=1, gamma=0.001, kernel=sigmoid;, score=0.000 total time=  25.0s\n",
      "[CV 2/5] END ..C=1, gamma=0.001, kernel=sigmoid;, score=0.110 total time=  26.9s\n",
      "[CV 3/5] END ..C=1, gamma=0.001, kernel=sigmoid;, score=0.110 total time=  26.0s\n",
      "[CV 4/5] END ..C=1, gamma=0.001, kernel=sigmoid;, score=0.110 total time=  24.8s\n",
      "[CV 5/5] END ..C=1, gamma=0.001, kernel=sigmoid;, score=0.110 total time=  26.1s\n",
      "[CV 1/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.312 total time=  31.8s\n",
      "[CV 2/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.267 total time=  29.1s\n",
      "[CV 3/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.253 total time=  31.5s\n",
      "[CV 4/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.319 total time=  29.3s\n",
      "[CV 5/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.282 total time=  28.2s\n",
      "[CV 1/5] END ...C=10, gamma=0.1, kernel=sigmoid;, score=0.358 total time=  23.1s\n",
      "[CV 2/5] END ...C=10, gamma=0.1, kernel=sigmoid;, score=0.383 total time=  22.2s\n",
      "[CV 3/5] END ...C=10, gamma=0.1, kernel=sigmoid;, score=0.331 total time=  22.3s\n",
      "[CV 4/5] END ...C=10, gamma=0.1, kernel=sigmoid;, score=0.409 total time=  21.6s\n",
      "[CV 5/5] END ...C=10, gamma=0.1, kernel=sigmoid;, score=0.373 total time=  21.1s\n",
      "[CV 1/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.431 total time=  17.2s\n",
      "[CV 2/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.459 total time=  17.5s\n",
      "[CV 3/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.444 total time=  17.2s\n",
      "[CV 4/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.458 total time=  17.3s\n",
      "[CV 5/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.414 total time=  17.0s\n",
      "[CV 1/5] END ..C=10, gamma=0.01, kernel=sigmoid;, score=0.439 total time=  19.6s\n",
      "[CV 2/5] END ..C=10, gamma=0.01, kernel=sigmoid;, score=0.451 total time=  19.5s\n",
      "[CV 3/5] END ..C=10, gamma=0.01, kernel=sigmoid;, score=0.441 total time=  19.1s\n",
      "[CV 4/5] END ..C=10, gamma=0.01, kernel=sigmoid;, score=0.444 total time=  19.2s\n",
      "[CV 5/5] END ..C=10, gamma=0.01, kernel=sigmoid;, score=0.400 total time=  19.0s\n",
      "[CV 1/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.359 total time=  23.7s\n",
      "[CV 2/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.419 total time=  25.6s\n",
      "[CV 3/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.392 total time=  27.0s\n",
      "[CV 4/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.383 total time=  24.0s\n",
      "[CV 5/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.367 total time=  24.2s\n",
      "[CV 1/5] END .C=10, gamma=0.001, kernel=sigmoid;, score=0.165 total time=  23.3s\n",
      "[CV 2/5] END .C=10, gamma=0.001, kernel=sigmoid;, score=0.164 total time=  23.2s\n",
      "[CV 3/5] END .C=10, gamma=0.001, kernel=sigmoid;, score=0.157 total time=  24.7s\n",
      "[CV 4/5] END .C=10, gamma=0.001, kernel=sigmoid;, score=0.109 total time=  28.7s\n",
      "[CV 5/5] END .C=10, gamma=0.001, kernel=sigmoid;, score=0.185 total time=  32.7s\n",
      "[CV 1/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.256 total time=  34.2s\n",
      "[CV 2/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.240 total time=  29.6s\n",
      "[CV 3/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.241 total time=  30.5s\n",
      "[CV 4/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.279 total time=  29.2s\n",
      "[CV 5/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.274 total time=  28.0s\n",
      "[CV 1/5] END ..C=100, gamma=0.1, kernel=sigmoid;, score=0.257 total time=  26.5s\n",
      "[CV 2/5] END ..C=100, gamma=0.1, kernel=sigmoid;, score=0.237 total time=  28.1s\n",
      "[CV 3/5] END ..C=100, gamma=0.1, kernel=sigmoid;, score=0.244 total time=  28.1s\n",
      "[CV 4/5] END ..C=100, gamma=0.1, kernel=sigmoid;, score=0.266 total time=  25.4s\n",
      "[CV 5/5] END ..C=100, gamma=0.1, kernel=sigmoid;, score=0.272 total time=  25.3s\n",
      "[CV 1/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.317 total time=  24.1s\n",
      "[CV 2/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.283 total time=  25.7s\n",
      "[CV 3/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.272 total time=  26.4s\n",
      "[CV 4/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.326 total time=  27.7s\n",
      "[CV 5/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.302 total time=  25.1s\n",
      "[CV 1/5] END .C=100, gamma=0.01, kernel=sigmoid;, score=0.354 total time=  22.9s\n",
      "[CV 2/5] END .C=100, gamma=0.01, kernel=sigmoid;, score=0.374 total time=  22.8s\n",
      "[CV 3/5] END .C=100, gamma=0.01, kernel=sigmoid;, score=0.331 total time=  23.3s\n",
      "[CV 4/5] END .C=100, gamma=0.01, kernel=sigmoid;, score=0.410 total time=  22.7s\n",
      "[CV 5/5] END .C=100, gamma=0.01, kernel=sigmoid;, score=0.374 total time=  21.9s\n",
      "[CV 1/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.430 total time=  18.0s\n",
      "[CV 2/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.458 total time=  18.4s\n",
      "[CV 3/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.444 total time=  19.9s\n",
      "[CV 4/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.457 total time=  18.6s\n",
      "[CV 5/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.412 total time=  17.8s\n",
      "[CV 1/5] END C=100, gamma=0.001, kernel=sigmoid;, score=0.439 total time=  20.1s\n",
      "[CV 2/5] END C=100, gamma=0.001, kernel=sigmoid;, score=0.451 total time=  20.6s\n",
      "[CV 3/5] END C=100, gamma=0.001, kernel=sigmoid;, score=0.441 total time=  20.6s\n",
      "[CV 4/5] END C=100, gamma=0.001, kernel=sigmoid;, score=0.444 total time=  20.7s\n",
      "[CV 5/5] END C=100, gamma=0.001, kernel=sigmoid;, score=0.400 total time=  20.0s\n",
      "Wall time: 36min 9s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=SVC(class_weight='balanced', random_state=20),\n",
       "             param_grid={'C': [1, 10, 100], 'gamma': [0.1, 0.01, 0.001],\n",
       "                         'kernel': ['rbf', 'sigmoid']},\n",
       "             scoring='f1', verbose=3)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# fit the grid search to our data\n",
    "grid_baseline.fit(tfidf_data_train, y_train)\n",
    "\n",
    "# this cell takes 48 minutes to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.44115028504856885\n",
      "Best Hyperparameters: {'C': 1, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "Model object with best parameters: \n",
      "SVC(C=1, class_weight='balanced', gamma=0.1, random_state=20)\n"
     ]
    }
   ],
   "source": [
    "# generate score with .best_score_ and hyperparemeters with .best_params_\n",
    "print('F1 Score:', grid_baseline.best_score_)\n",
    "print('Best Hyperparameters:', grid_baseline.best_params_)\n",
    "print('Model object with best parameters: ')\n",
    "print(grid_baseline.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The grid search found that the best hyperparameters are `{'C': 1, 'gamma': 0.1, 'kernel': 'rbf'}`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned SVM Model Predictions\n",
      "F1 on train set: 0.7077399380804954\n",
      "F1 on test set: 0.38513513513513514\n"
     ]
    }
   ],
   "source": [
    "# Predict the response for test dataset\n",
    "grid_base_y_pred_train = grid_baseline.best_estimator_.predict(tfidf_data_train)\n",
    "\n",
    "# predict the training set\n",
    "grid_base_y_pred_test = grid_baseline.best_estimator_.predict(tfidf_data_test)\n",
    "\n",
    "# Model F1, how often is the classifier correct?\n",
    "print('Tuned SVM Model Predictions')\n",
    "print(\"F1 on train set:\",metrics.f1_score(y_train, grid_base_y_pred_train))\n",
    "print(\"F1 on test set:\",metrics.f1_score(y_test, grid_base_y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting variables for evaluation metrics\n",
    "grid_accuracy = accuracy_score(y_test, grid_base_y_pred_test)\n",
    "grid_precision = precision_score(y_test, grid_base_y_pred_test)\n",
    "grid_recall = recall_score(y_test, grid_base_y_pred_test)\n",
    "grid_f1_score = f1_score(y_test, grid_base_y_pred_test)\n",
    "grid_weighted_f1_score = f1_score(y_test, grid_base_y_pred_test, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding these metrics to evaluation metric dict\n",
    "metric_dict['Grid Search SVM'] = {'accuracy': grid_accuracy, 'precision': grid_precision, 'recall': grid_recall, 'f1_score': grid_f1_score, 'weighted_f1': grid_weighted_f1_score}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>weighted_f1</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Baseline SVM</th>\n",
       "      <td>0.360947</td>\n",
       "      <td>0.437276</td>\n",
       "      <td>0.395462</td>\n",
       "      <td>0.928112</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline SVM Oversampled with SMOTE</th>\n",
       "      <td>0.343750</td>\n",
       "      <td>0.275986</td>\n",
       "      <td>0.306163</td>\n",
       "      <td>0.925951</td>\n",
       "      <td>0.929595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline SVM Undersampled with Tomek Links</th>\n",
       "      <td>0.656250</td>\n",
       "      <td>0.225806</td>\n",
       "      <td>0.336000</td>\n",
       "      <td>0.937993</td>\n",
       "      <td>0.949768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Grid Search SVM</th>\n",
       "      <td>0.280788</td>\n",
       "      <td>0.612903</td>\n",
       "      <td>0.385135</td>\n",
       "      <td>0.908306</td>\n",
       "      <td>0.889853</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            precision    recall  f1_score  \\\n",
       "Baseline SVM                                 0.360947  0.437276  0.395462   \n",
       "Baseline SVM Oversampled with SMOTE          0.343750  0.275986  0.306163   \n",
       "Baseline SVM Undersampled with Tomek Links   0.656250  0.225806  0.336000   \n",
       "Grid Search SVM                              0.280788  0.612903  0.385135   \n",
       "\n",
       "                                            weighted_f1  accuracy  \n",
       "Baseline SVM                                   0.928112       NaN  \n",
       "Baseline SVM Oversampled with SMOTE            0.925951  0.929595  \n",
       "Baseline SVM Undersampled with Tomek Links     0.937993  0.949768  \n",
       "Grid Search SVM                                0.908306  0.889853  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# comparing with other models\n",
    "pd.DataFrame.from_dict(metric_dict, orient='index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, the model with grid searched hyperparameters didn't perform better than the baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
